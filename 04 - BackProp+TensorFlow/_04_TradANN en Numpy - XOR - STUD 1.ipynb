{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red neuronal artificial desde cero en Numpy - Problema del XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mezcla entre los videos de Siraj Raval y de Andrew Ng\n",
    "- https://www.youtube.com/watch?v=vcZub77WvFA\n",
    "- https://www.youtube.com/watch?v=262XJe2I2D0\n",
    "- https://www.coursera.org/learn/neural-networks-deep-learning/lecture/6dDj7/backpropagation-intuition-optional\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear un clasificador binario que podrá aprender la solución a la operación de XOR, utilizando una red neuronal artificial con una capa escondida que sigue la estructura presentada en la siguiente imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"04_TradANNDesdeCero.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ilustrar el procedimiento de back-propagation vamos a utilizar solamente funciones activación sigmoide, y vamos a utilizar numpy para ilustrar las operaciones matemáticas matriciales básicas con numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #operaciones matriciales y con vectores\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la función sigmoide y su función gradiente basada en si misma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoide(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoideGrad(x):\n",
    "    return x*(1-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos datos sintéticos (XOR sobre las dos primeras columnas) y especificamos los parámetros de la red neuronal. Incluimos una tercera columna para mostrar que la red resultante aprende a ignorar los atributos que no son importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X [[0 0 1 1 0 0 1 1]\n",
      " [0 1 0 1 0 1 0 1]\n",
      " [1 1 1 1 0 0 0 0]]\n",
      "y [0 1 1 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Queremos que cada dato registro sea un vector de 3 posiciones. \n",
    "# Tenemos aquí 8 registros apilados horizontalmente gracias a la transposición del array incialmente creado\n",
    "X = np.transpose(np.array([\n",
    "    [0,0,1],\n",
    "    [0,1,1],\n",
    "    [1,0,1],\n",
    "    [1,1,1],\n",
    "    [0,0,0],\n",
    "    [0,1,0],\n",
    "    [1,0,0],\n",
    "    [1,1,0]\n",
    "]))\n",
    "print(\"X\", X)\n",
    "\n",
    "y = np.array([\n",
    "    0, \n",
    "    1, \n",
    "    1, \n",
    "    0,\n",
    "    0, \n",
    "    1, \n",
    "    1, \n",
    "    0])\n",
    "print(\"y\", y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialización de los parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializamos los pesos de la red aleatoriamente para la capa intermedia (1) y la capa de salida (2). La capa inicial no tiene pesos pues consiste únicamente de los datos de entrada.\n",
    "\n",
    "La primera capa tiene 4 neuronas y 3 inputs, creamos una matriz de pesos w1 con 4 filas y 3 columnas. Tenemos además un vector b1 con 4 posiciones.\n",
    "\n",
    "La segunda capa tiene 1 neurona y 4 inputs, creamos una matriz de pesos w2 con 1 fila y 4 columnas. Tenemos además un vector b2 con 1 posición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initParams():\n",
    "    np.random.seed(123456)\n",
    "\n",
    "    # El -0.5 permite que los valores queden centrados en 0\n",
    "    w1 = 2*np.random.random((4, 3))-1\n",
    "    w2 = 2*np.random.random((1, 4))-1\n",
    "    b1 = 2*np.random.random((4, 1))-1\n",
    "    b2 = 2*np.random.random((1, 1))-1\n",
    "    return(w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1: {[[-0.74606033  0.93343568 -0.47904799]\n",
      " [ 0.79447305 -0.24650057 -0.32755651]\n",
      " [-0.09724706  0.68051017 -0.75379571]\n",
      " [ 0.0860524  -0.25397555 -0.10400635]]}\n",
      "b1: {[[-0.54222539]\n",
      " [ 0.5535675 ]\n",
      " [ 0.18956718]\n",
      " [-0.72489289]]}\n",
      "w2: {[[-0.74111864  0.71975741  0.64077673 -0.29589292]]}\n",
      "b2: {[[0.70579956]]}\n"
     ]
    }
   ],
   "source": [
    "w1, b1, w2, b2 = initParams()\n",
    "print(\"w1: {%s}\\nb1: {%s}\" % (w1, b1))\n",
    "print(\"w2: {%s}\\nb2: {%s}\" % (w2, b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos por definir la función feedForward, que recibe la matriz de inputs con todos los registros y retorna el vector con las predicciones correspondientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedForward(X, w1, b1, w2, b2):\n",
    "    '''Calcula el valor predicho para todos los registros que se encuentran en X\n",
    "       -----------\n",
    "       Argumentos:\n",
    "       X: matriz con los inputs, con tantas filas como atributos y tantas columnas como registros\n",
    "       w1: matriz con los pesos de las conexiones entrantes de la 1a capa, \n",
    "         con tantas filas como atributos y tantas columnas como registros\n",
    "       b1: array con los sesgos de las neuronas de la 1a capa\n",
    "       w2: matriz con los pesos de las conexiones entrantes de la 2a capa, \n",
    "         con tantas filas como atributos y tantas columnas como registros\n",
    "       b2: array con los sesgos de las neuronas de la 2a capa\n",
    "       -----------\n",
    "       Retorna:\n",
    "       a1: matriz con las activaciones de la capa escondida, \n",
    "         con tantas filas como neuronas de la capa y tantas columnas como registros\n",
    "       a2 (y estimado): vector con las predicciones\n",
    "    '''\n",
    "    ...\n",
    "    ...\n",
    "    ...\n",
    "    \n",
    "    return (a1, a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos entonces evaluar el estado inicial de la red (con sus parámetros inicales):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.52068432]\n",
      " [0.49822742]\n",
      " [0.57914146]\n",
      " [0.56160151]\n",
      " [0.54035237]\n",
      " [0.51996802]\n",
      " [0.60057781]\n",
      " [0.58093636]]\n"
     ]
    }
   ],
   "source": [
    "a1, a2 = feedForward(X, w1, b1, w2, b1)\n",
    "y_est = a2\n",
    "print(y_est.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que los datos están bastante alejados de la realidad [0, 1, 1, 0, 0, 1, 1, 0]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de costo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costoGlobal(y_real, y_est): \n",
    "    '''Calcula el costo global de la predicción con la red actual, comparando la clase real con las probabilidad estimadas\n",
    "       -----------\n",
    "       Argumentos:\n",
    "       y_real: array con las clases reales de los datos\n",
    "       y_est: array con las probabilidades de salida estimadas por la red\n",
    "       -----------\n",
    "       Retorna:\n",
    "       costo: promedio de los costos de cada predicción individual\n",
    "    '''\n",
    "    ...\n",
    "    \n",
    "    return costo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7017260765032634"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costo = costoGlobal(y, y_est)\n",
    "costo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
