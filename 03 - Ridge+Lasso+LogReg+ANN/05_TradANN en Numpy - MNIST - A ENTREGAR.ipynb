{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red neuronal artificial en Numpy - MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bibliografía:\n",
    "- Deep Learning with Python (capítulo 2), Francois Chollet, 2018 Manning\n",
    "- https://www.coursera.org/learn/neural-networks-deep-learning/lecture/6dDj7/backpropagation-intuition-optional, Andrew Ng, 2018 DeepLearning.ai\n",
    "- Learning Tensor Flow, Tom Hope, Yehezkel S. Resheff & Itay Lieder, 2017 O'Reilly\n",
    "- TensorFlow for Deep Learning, Bharath Ramsundar & Reza Bosagh Zadeh, 2018, O'Reilly\n",
    "- Python Machine Learning, 2nd ed. (capítulo 13), Sebastian Rachska, 2017 Packt\n",
    "- Machine Learning with TensrFlow (capítulo 7), Nishant Shukla, 2018 Manning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos en este notebook a implementar una red neuronal que permita la clasificación de imágenes de dígitos en escala de grises, utilizando tres niveles de extracción de programación.\n",
    "\n",
    "Además de utilizar **numpy**, aprovechamos para presentar las librerías **tensorflow** y **keras** a través de su aplicación al problema de clasificación mencionado. \n",
    "El modelo a implementar es una red con una capa escondida de 512 neuronas utilizando la función de activación **ReLU** y 10 neuronas de salida utilizando la función de activación **softmax**.\n",
    "\n",
    "Vamos a seguir un protocolo de *holdout* para evaluar los clasificadores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploración y entendimiento del dataset MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras necesita una base para trabajar. Vamos a usar tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras viene con MNIST directamente integrada. Las imagenes y sus etiquetas (clases) ya vienen particionadas en training y test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "        18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "         0,   0], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0][5] #La primera imagen, la 6a fila, muestra los 28 valores de gris (uno por cada columna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera dimension del tensor de train_images es de 60000, pues hay 60000 imagenes, las 2 siguientes dimensiones son las que dan el tamaño de las imágenes (28x28). Como son imagenes en escala de grises, no hay una 4a dimensión que tendría el canal de color (e.g. RGB). Cada valor de la matriz de 28x28 es una valor de gris de 0 a 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El testset tiene 10000 imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver cada una de las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit = train_images[4]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitamos que los datos de entrenamiento y test estén en el formato dado por la capa de entrada de la red, donde se reciben los datos representados a partir de un tensor cuya primera dimensión tiene 784 neuronas, es decir, recibe como input instancias representadas por tensores con dimensionalidad (784,).\n",
    "\n",
    "Cómo los datos de entrenamiento están en tensores de 60000x28x28, es necesario convertirlos en un tensor de 60000x784. Idem para el tensor de test.\n",
    "\n",
    "Vamos también a modificar la escala de grises, que originalmente va de 0 a 255, a una escala que vaya de 0 a 1. Para esto, dividimos los valores originales por 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la estructura de la red (número de neuronas por capa y número de inputs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n0 = 28*28\n",
    "n1 = 512\n",
    "n2 = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a aplanar los datos de train y test para poder utilizar cada pixel como un predictor (cada pixel en una columna diferente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las etiquetas están en valores numéricos, vamos codificarlos en one hot encoding, con un vector de K posiciones para K clases, donde la clase específica de cada ejemplo tiene un valor de 1, y las demas posiciones del vector tienen valores de 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como los labels están desordenados y no responde a ninguna organización sistemática, los podemos dejar así. Si siguieran un orden definido, sería necesario barajarlos para que el orden no influyera en el aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_images.T\n",
    "y_train = train_labels.T\n",
    "m=X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST: ANN con Numpy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos las funciones de activación y sus gradientes.\n",
    "\n",
    "La función de activación de softmax solo se puede utilizar en la última capa y generaliza la función sigmoide, por lo que su gradiente es el mismo que el del caso binario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoide(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoideGrad(x):\n",
    "    return x*(1-x)\n",
    "\n",
    "def softmax(X):\n",
    "    ...TODO...\n",
    "    return ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    ...TODO...\n",
    "    return ...\n",
    "\n",
    "def tanhGrad(x):\n",
    "    ...TODO...\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    ...TODO...\n",
    "    return ...\n",
    "\n",
    "def reluGrad(x):\n",
    "    ...TODO...\n",
    "    return ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialización de los parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializamos los pesos de la red aleatoriamente para la capa intermedia (1) y la capa de salida (2). La capa inicial no tiene pesos pues consiste únicamente de los datos de entrada.\n",
    "\n",
    "La primera capa tiene n1 (512) neuronas y n0 (784) inputs, creamos una matriz de pesos w1 con n1 filas y n0 columnas. Tenemos además un vector b1 con n1 posiciones.\n",
    "\n",
    "La segunda capa tiene n2 (10) neuronas y n1 (512) inputs, creamos una matriz de pesos w2 con n2 fila y n1 columnas. Tenemos además un vector b2 con n2 posiciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initParams():\n",
    "    np.random.seed(123456)\n",
    "\n",
    "    ...TODO...\n",
    "\n",
    "    return(w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  (60000, 784)\n",
      "w1: {(512, 784)}\n",
      "b1: {(512, 1)}\n",
      "w2: {(10, 512)}\n",
      "b2: {(10, 1)}\n"
     ]
    }
   ],
   "source": [
    "w1, b1, w2, b2 = initParams()\n",
    "print(\"inputs: \", train_images.shape)\n",
    "print(\"w1: {%s}\\nb1: {%s}\" % (w1.shape, b1.shape))\n",
    "print(\"w2: {%s}\\nb2: {%s}\" % (w2.shape, b2.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos por definir la función feedForward, que recibe la matriz de inputs con todos los registros y retorna el vector con las predicciones correspondientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedForward(X, w1, b1, w2, b2):\n",
    "    '''Calcula el valor predicho para todos los registros que se encuentran en X\n",
    "       -----------\n",
    "       Argumentos:\n",
    "       X: matriz con los inputs, con tantas filas como atributos y tantas columnas como registros\n",
    "       w1: matriz con los pesos de las conexiones entrantes de la 1a capa, \n",
    "         con tantas filas como atributos y tantas columnas como registros\n",
    "       b1: array con los sesgos de las neuronas de la 1a capa\n",
    "       w2: matriz con los pesos de las conexiones entrantes de la 2a capa, \n",
    "         con tantas filas como atributos y tantas columnas como registros\n",
    "       b2: array con los sesgos de las neuronas de la 2a capa\n",
    "       -----------\n",
    "       Retorna:\n",
    "       a1: matriz con las activaciones de la capa escondida, \n",
    "         con tantas filas como neuronas de la capa y tantas columnas como registros\n",
    "       a2 (y estimado): vector con las predicciones\n",
    "    '''\n",
    "\n",
    "    ...TODO...\n",
    "\n",
    "    return (a1, a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos entonces evaluar el estado inicial de la red (con sus parámetros iniciales):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10071491 0.10042403 0.10197454 ... 0.09950268 0.09953592 0.10050975]\n",
      " [0.09982152 0.09917264 0.10177136 ... 0.09984397 0.0986228  0.10154716]\n",
      " [0.10044414 0.09944697 0.10062615 ... 0.10005185 0.09904903 0.09962872]\n",
      " ...\n",
      " [0.10024492 0.1008202  0.10049123 ... 0.09974311 0.10031068 0.09981346]\n",
      " [0.10037734 0.09966835 0.10097462 ... 0.09993777 0.09929817 0.10047747]\n",
      " [0.09963554 0.10080644 0.10104211 ... 0.09960428 0.09928018 0.10077153]]\n"
     ]
    }
   ],
   "source": [
    "a1, a2 = feedForward(X_train, w1, b1, w2, b1)\n",
    "print(a2.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que casi todas las probabilidades son cercanas al 10%, por lo que no hay inicialmente ninguna predilección definida por ninguno de los dígitos del 0 al 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de costo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función de perdida es la **categorical_crossentropy**, que se utiliza en el caso de problemas de clasificación multiclase. El optimizador tratará de minimizarla. Es una función de distancia entre el valor real (que solo tiene una de las dimensiones con un 1 y las demás con un 0) y el predicho por el modelo (que tiene una distribución que probablemente no sea absoluta, sino que reparta la unidad de probabilidad en cada una de las clases).\n",
    "Esta función es la suma negativa de las entropias de cada una de las posiciones del vector one hot encoded de clases:\n",
    "$$H(y,\\tilde{y}) =-\\sum{y*log(\\tilde{y})}$$\n",
    "Como el valor de *y* es solo 1 en una de las posiciondes del vector de clases y 0 en las demás, solo una posición será considerada, de tal manera que la similitud entre los valores reales (1) y predichos (fracción de 1) es dada por el log del valor predicho para la clase real.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costoGlobal(y_real, y_est): \n",
    "    '''Calcula el costo global de la predicción con la red actual, comparando la clase real con las probabilidad estimadas\n",
    "       -----------\n",
    "       Argumentos:\n",
    "       y_real: Matriz con las clases reales de los datos. numcols = registros, numrows = 10\n",
    "       y_est: array con las probabilidades de salida estimadas por la red\n",
    "       -----------\n",
    "       Retorna:\n",
    "       costo: promedio de los costos de cada predicción individual\n",
    "    '''\n",
    "    \n",
    "    ...TODO...\n",
    "\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8408622903772436e-05"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costo = costoGlobal(y_train, a2)\n",
    "costo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backProp(X, y, w1, b1, w2, b2, a1, a2): \n",
    "    '''Calcula los deltas de las actualizaciones de los parámetros de las capas \n",
    "       -----------\n",
    "       Argumentos:\n",
    "       X: matriz con los inputs, con tantas filas como atributos y tantas columnas como registros\n",
    "       y: array con los valores reales a predecir\n",
    "       w1: matriz con los pesos de las conexiones entrantes de la 1a capa, \n",
    "         con tantas filas como atributos y tantas columnas como registros\n",
    "       w2: matriz con los pesos de las conexiones entrantes de la 2a capa, \n",
    "         con tantas filas como atributos y tantas columnas como registros\n",
    "       b1: array con los sesgos de las neuronas de la 1a capa\n",
    "       b2: array con los sesgos de las neuronas de la 2a capa\n",
    "       a1: matriz con las activaciones de la capa escondida, con tantas filas como neuronas de la capa y tantas columnas como registros\n",
    "       a2 (y estimado): matriz con las predicciones, con tantas columnas como registros y 10 filas (1 por cada dígito)\n",
    "       -----------\n",
    "       Retorna:\n",
    "       dw1: matriz con las actualizaciones que se deben aplicar a los coeficientes de la capa 1 (hidden)\n",
    "       db1: array con las actualizaciones que se deben aplicar a los sesgos de la capa 1 (hidden)\n",
    "       dw2: matriz con las actualizaciones que se deben aplicar a los coeficientes de la capa 2 (salida)\n",
    "       db2: array con las actualizaciones que se deben aplicar a los sesgos de la capa 2 (salida)\n",
    "    '''\n",
    "\n",
    "    ...TODO...\n",
    "\n",
    "    return (dw1, db1, dw2, db2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw1, db1, dw2, db2 = backProp(X_train, y_train, w1, b1, w2, b2, a1, a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ciclo de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ahora a programar el ciclo (época) de back propagation.\n",
    "- Se calculan los valores intermediarios en la fase forward: a0 (son las entradas X), a1 y a2 (las salidas estimadas y_est)\n",
    "- Se calcula el error de cada época\n",
    "- Se encuentran los valores de los gradientes en la fase backward a partir de los resultados anteriores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos los hiperparámetros del modelo, utilizados para aprender los pesos de las capas (los verdaderos parámetros)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5 # learning rate\n",
    "epocas = 100 # Iteraciones de backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenarRed(epocas, lr, X, y, w1, b1, w2, b2, a1, a2, echo_progression=True):\n",
    "    for i in range(epocas):\n",
    "\n",
    "        ...TODO...\n",
    "        \n",
    "    return (costo, w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca %d, costo = %10.8f 0 3.8408622903772436e-05\n",
      "Epoca %d, costo = %10.8f 10 2.7411510408127332e-05\n",
      "Epoca %d, costo = %10.8f 20 1.324481886758361e-05\n",
      "Epoca %d, costo = %10.8f 30 9.572798210976057e-06\n",
      "Epoca %d, costo = %10.8f 40 8.046299617226456e-06\n",
      "Epoca %d, costo = %10.8f 50 7.217797516259726e-06\n",
      "Epoca %d, costo = %10.8f 60 6.705699346742406e-06\n",
      "Epoca %d, costo = %10.8f 70 6.357649585970123e-06\n",
      "Epoca %d, costo = %10.8f 80 6.103382347304558e-06\n",
      "Epoca %d, costo = %10.8f 90 5.907515773805755e-06\n"
     ]
    }
   ],
   "source": [
    "costo, w1, b1, w2, b2 = entrenarRed(epocas, lr, X_train, y_train, w1, b1, w2, b2, a1, a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestras predicciones finales son: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5690    0   58   23   15  101   48   39   33   46]\n",
      " [   0 6519   78   33   34   44   21   64  142   33]\n",
      " [  33   32 5182  141   35   35   67   89   81   29]\n",
      " [  16   32  104 5361    4  245    3   24  176   79]\n",
      " [  13    6  110    4 5350   69   68   66   31  211]\n",
      " [  52   31   16  260    6 4465   83   10  189   42]\n",
      " [  40    9  132   32   75  127 5585    2   53    5]\n",
      " [  10   19   86   79   10   28    0 5732   20  226]\n",
      " [  63   86  165  125   35  233   42   19 5028   60]\n",
      " [   6    8   27   73  278   74    1  220   98 5218]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.94      0.95      6053\n",
      "          1       0.97      0.94      0.95      6968\n",
      "          2       0.87      0.91      0.89      5724\n",
      "          3       0.87      0.89      0.88      6044\n",
      "          4       0.92      0.90      0.91      5928\n",
      "          5       0.82      0.87      0.84      5154\n",
      "          6       0.94      0.92      0.93      6060\n",
      "          7       0.91      0.92      0.92      6210\n",
      "          8       0.86      0.86      0.86      5856\n",
      "          9       0.88      0.87      0.87      6003\n",
      "\n",
      "avg / total       0.90      0.90      0.90     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, a2 = feedForward(X_train, w1, b1, w2, b1)\n",
    "\n",
    "y_pred = np.argmax(a2, axis=0)\n",
    "y_real = np.argmax(y_train, axis=0)\n",
    "print(confusion_matrix(y_pred, y_real))\n",
    "print(classification_report(y_pred, y_real))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos como nos va con el set de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_images.T\n",
    "y_test = test_labels.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 957    0   12    5    1   17   17    6    8   11]\n",
      " [   0 1107    9    0    1    3    3   14    8    8]\n",
      " [   4    1  902   21    6    4    7   25    9    5]\n",
      " [   2    4   17  898    1   49    0    5   28   11]\n",
      " [   0    1   14    0  907   11   13    8   10   41]\n",
      " [   7    1    1   38    0  740   16    0   31   13]\n",
      " [   7    4   15    1   12   15  896    0   13    0]\n",
      " [   1    1   13   18    2    9    1  930   11   30]\n",
      " [   2   16   43   21    8   37    5    4  841    4]\n",
      " [   0    0    6    8   44    7    0   36   15  886]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.93      0.95      1034\n",
      "          1       0.98      0.96      0.97      1153\n",
      "          2       0.87      0.92      0.89       984\n",
      "          3       0.89      0.88      0.89      1015\n",
      "          4       0.92      0.90      0.91      1005\n",
      "          5       0.83      0.87      0.85       847\n",
      "          6       0.94      0.93      0.93       963\n",
      "          7       0.90      0.92      0.91      1016\n",
      "          8       0.86      0.86      0.86       981\n",
      "          9       0.88      0.88      0.88      1002\n",
      "\n",
      "avg / total       0.91      0.91      0.91     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, a2 = feedForward(X_test, w1, b1, w2, b1)\n",
    "\n",
    "y_pred = np.argmax(a2, axis=0)\n",
    "y_real = np.argmax(y_test, axis=0)\n",
    "print(confusion_matrix(y_pred, y_real))\n",
    "print(classification_report(y_pred, y_real))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
